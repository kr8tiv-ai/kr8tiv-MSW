---
phase: 02-auto-conversation-engine
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/auto-conversation/relevance-scorer.ts
  - package.json
autonomous: true

must_haves:
  truths:
    - "RelevanceScorer connects to local Ollama and returns structured relevance scores"
    - "Scores have 4 dimensions (taskRelevance, errorRelevance, implementationValue, novelty) summing to total 0-100"
    - "Engine initialization verifies Ollama is running and model is available, with clear error messages if not"
    - "Model is warmed up on first init to avoid cold-start latency during expansion"
  artifacts:
    - path: "src/auto-conversation/relevance-scorer.ts"
      provides: "RelevanceScorer class with Ollama-based scoring"
      exports: ["RelevanceScorer"]
    - path: "package.json"
      provides: "ollama, zod, zod-to-json-schema dependencies"
      contains: "ollama"
  key_links:
    - from: "src/auto-conversation/relevance-scorer.ts"
      to: "ollama"
      via: "import ollama from 'ollama'"
      pattern: "import.*ollama"
---

<objective>
Implement the RelevanceScorer that uses a local Ollama LLM to score candidate topics for relevance before clicking them.

Purpose: This is the intelligence layer — it prevents wasting queries on low-value topics. Uses structured JSON output via Zod schemas for type-safe scoring.
Output: Working RelevanceScorer class with Ollama integration.
</objective>

<execution_context>
@C:\Users\lucid\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\lucid\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-auto-conversation-engine/02-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install dependencies</name>
  <files>package.json</files>
  <action>
Install the Ollama and schema dependencies:
```bash
npm install ollama zod zod-to-json-schema
```
These are production dependencies (not dev).
  </action>
  <verify>`npm ls ollama zod zod-to-json-schema` shows all three installed</verify>
  <done>Dependencies installed</done>
</task>

<task type="auto">
  <name>Task 2: RelevanceScorer implementation</name>
  <files>src/auto-conversation/relevance-scorer.ts</files>
  <action>
Create RelevanceScorer class:

**Zod schema:** Define `RelevanceScoreSchema` using zod:
```typescript
const RelevanceScoreSchema = z.object({
  taskRelevance: z.number().min(0).max(40),
  errorRelevance: z.number().min(0).max(30),
  implementationValue: z.number().min(0).max(20),
  novelty: z.number().min(0).max(10),
  total: z.number().min(0).max(100),
  reasoning: z.string(),
});
```

**Constructor:** Takes `{ model: string }` (default `'qwen2.5:1.5b'`).

**`initialize(): Promise<void>`:**
1. Call `ollama.list()` — if ECONNREFUSED, throw clear error: "Ollama is not running. Start with `ollama serve`"
2. Check if model is in the list — if not, throw: "Model X not found. Pull with `ollama pull X`"
3. Warm up model with a dummy chat call (use `format: 'json'`)
4. Log "Relevance model ready"

**`score(candidateTopic: string, taskGoal: string, currentError: string | null, previousTopics: string[]): Promise<ScoredTopic>`:**
1. Build prompt from research Pattern 2 (include taskGoal, currentError if present, previousTopics list, candidateTopic)
2. Call `ollama.chat()` with:
   - model: this.model
   - messages: [{ role: 'user', content: prompt }]
   - format: zodToJsonSchema(RelevanceScoreSchema)
3. Parse response with `RelevanceScoreSchema.parse(JSON.parse(response.message.content))`
4. If parse fails, return a fallback score of 0 with reasoning "Failed to parse LLM response"
5. Return as ScoredTopic (import type from types.ts — create partial Topic with score and dimensions)

**`dispose(): Promise<void>`:** No-op for now (Ollama manages its own lifecycle).

Import `ScoredTopic` from `./types`. Use try/catch around all Ollama calls with meaningful error messages.
  </action>
  <verify>`npx tsc --noEmit src/auto-conversation/relevance-scorer.ts` compiles without errors</verify>
  <done>RelevanceScorer initializes Ollama, validates model availability, and returns structured relevance scores</done>
</task>

</tasks>

<verification>
- `npx tsc --noEmit` passes
- RelevanceScorer exports single class
- Zod schema enforces dimension ranges (0-40, 0-30, 0-20, 0-10)
- Error messages are actionable (tell user exactly what to run)
</verification>

<success_criteria>
RelevanceScorer connects to Ollama, validates environment, and produces typed relevance scores for candidate topics.
</success_criteria>

<output>
After completion, create `.planning/phases/02-auto-conversation-engine/02-02-SUMMARY.md`
</output>
