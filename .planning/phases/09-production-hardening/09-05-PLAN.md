---
phase: 09-production-hardening
plan: 05
type: execute
wave: 2
depends_on: ["09-01"]
files_modified:
  - src/metrics/index.ts
  - src/metrics/collector.ts
  - src/metrics/exporter.ts
  - src/metrics/stats.ts
autonomous: true

must_haves:
  truths:
    - "Performance metrics are collected using Node.js perf_hooks"
    - "Metrics can be exported to JSON files in .msw/"
    - "Statistics include min/max/avg/p50/p95/p99 for each metric"
    - "Metrics collection does not block the event loop"
  artifacts:
    - path: "src/metrics/collector.ts"
      provides: "Performance measurement with perf_hooks"
      exports: ["MetricsCollector", "startMeasure", "endMeasure"]
    - path: "src/metrics/stats.ts"
      provides: "Statistical aggregation utilities"
      exports: ["calculateStats", "MetricStats"]
    - path: "src/metrics/exporter.ts"
      provides: "JSON export functionality"
      exports: ["exportMetrics", "MetricsExport"]
    - path: "src/metrics/index.ts"
      provides: "Barrel export for metrics module"
      exports: ["MetricsCollector", "exportMetrics"]
  key_links:
    - from: "src/metrics/collector.ts"
      to: "node:perf_hooks"
      via: "Performance API usage"
      pattern: "import.*perf_hooks"
    - from: "src/metrics/exporter.ts"
      to: ".msw/metrics-*.json"
      via: "JSON file export"
      pattern: "metrics-.*\\.json"
---

<objective>
Implement performance metrics tracking using Node.js perf_hooks with JSON export capability.

Purpose: Enable performance analysis and optimization by collecting timing metrics for key operations, with statistical aggregation and file export for analysis.

Output: Complete metrics module (`src/metrics/`) with collector, statistical calculations, and JSON export.
</objective>

<execution_context>
@C:\Users\lucid\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\lucid\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-production-hardening/09-RESEARCH.md
@.planning/phases/09-production-hardening/09-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement statistical utilities</name>
  <files>
    src/metrics/stats.ts
  </files>
  <action>
Create `src/metrics/` directory and implement statistical utilities:

**src/metrics/stats.ts:**
```typescript
export interface MetricStats {
  name: string;
  count: number;
  min: number;
  max: number;
  avg: number;
  sum: number;
  p50: number;
  p90: number;
  p95: number;
  p99: number;
  stdDev: number;
}

/**
 * Calculate percentile from sorted array.
 */
export function percentile(sortedValues: number[], p: number): number {
  if (sortedValues.length === 0) return 0;
  if (sortedValues.length === 1) return sortedValues[0];

  const index = Math.ceil((p / 100) * sortedValues.length) - 1;
  return sortedValues[Math.max(0, Math.min(index, sortedValues.length - 1))];
}

/**
 * Calculate standard deviation.
 */
export function standardDeviation(values: number[], avg: number): number {
  if (values.length <= 1) return 0;

  const squaredDiffs = values.map((v) => Math.pow(v - avg, 2));
  const avgSquaredDiff = squaredDiffs.reduce((a, b) => a + b, 0) / values.length;
  return Math.sqrt(avgSquaredDiff);
}

/**
 * Calculate comprehensive statistics for a set of metric values.
 */
export function calculateStats(name: string, values: number[]): MetricStats {
  if (values.length === 0) {
    return {
      name,
      count: 0,
      min: 0,
      max: 0,
      avg: 0,
      sum: 0,
      p50: 0,
      p90: 0,
      p95: 0,
      p99: 0,
      stdDev: 0,
    };
  }

  const sorted = [...values].sort((a, b) => a - b);
  const sum = values.reduce((a, b) => a + b, 0);
  const avg = sum / values.length;

  return {
    name,
    count: values.length,
    min: sorted[0],
    max: sorted[sorted.length - 1],
    avg: Math.round(avg * 100) / 100, // Round to 2 decimals
    sum: Math.round(sum * 100) / 100,
    p50: percentile(sorted, 50),
    p90: percentile(sorted, 90),
    p95: percentile(sorted, 95),
    p99: percentile(sorted, 99),
    stdDev: Math.round(standardDeviation(values, avg) * 100) / 100,
  };
}

/**
 * Format stats for human-readable display.
 */
export function formatStats(stats: MetricStats): string {
  return `
${stats.name} (${stats.count} samples):
  Min: ${stats.min.toFixed(2)}ms
  Max: ${stats.max.toFixed(2)}ms
  Avg: ${stats.avg.toFixed(2)}ms
  P50: ${stats.p50.toFixed(2)}ms
  P95: ${stats.p95.toFixed(2)}ms
  P99: ${stats.p99.toFixed(2)}ms
  StdDev: ${stats.stdDev.toFixed(2)}ms
`;
}
```
  </action>
  <verify>
- `npx tsc --noEmit` passes
- File exists at `src/metrics/stats.ts`
  </verify>
  <done>Statistical utilities implemented for metric aggregation</done>
</task>

<task type="auto">
  <name>Task 2: Implement metrics collector with perf_hooks</name>
  <files>
    src/metrics/collector.ts
    src/metrics/exporter.ts
    src/metrics/index.ts
  </files>
  <action>
**src/metrics/collector.ts:**
```typescript
import {
  performance,
  PerformanceObserver,
  type PerformanceEntry,
} from "node:perf_hooks";
import { calculateStats, type MetricStats } from "./stats.js";

export interface MetricEntry {
  name: string;
  duration: number;
  startTime: number;
  timestamp: string;
}

const MAX_ENTRIES = 10000; // Prevent memory leak

/**
 * Metrics collector using Node.js perf_hooks (HARD-05).
 * Non-blocking performance measurement.
 */
export class MetricsCollector {
  private entries: MetricEntry[] = [];
  private observer?: PerformanceObserver;
  private readonly maxEntries: number;

  constructor(maxEntries: number = MAX_ENTRIES) {
    this.maxEntries = maxEntries;
    this.setupObserver();
  }

  private setupObserver(): void {
    this.observer = new PerformanceObserver((list) => {
      for (const entry of list.getEntries()) {
        this.recordEntry(entry);
      }
    });
    this.observer.observe({ entryTypes: ["measure"] });
  }

  private recordEntry(entry: PerformanceEntry): void {
    // Enforce max entries to prevent memory leak
    if (this.entries.length >= this.maxEntries) {
      // Remove oldest 10%
      const removeCount = Math.floor(this.maxEntries * 0.1);
      this.entries.splice(0, removeCount);
    }

    this.entries.push({
      name: entry.name,
      duration: entry.duration,
      startTime: entry.startTime,
      timestamp: new Date().toISOString(),
    });
  }

  /**
   * Start a timing measurement.
   * @returns Mark name for use with endMeasure()
   */
  startMeasure(name: string): string {
    const markName = `${name}-start-${Date.now()}`;
    performance.mark(markName);
    return markName;
  }

  /**
   * End a timing measurement and record the duration.
   * @returns Duration in milliseconds
   */
  endMeasure(name: string, startMark: string): number {
    const endMark = `${name}-end-${Date.now()}`;
    performance.mark(endMark);

    try {
      const measure = performance.measure(name, startMark, endMark);
      return measure.duration;
    } finally {
      // Clean up marks
      performance.clearMarks(startMark);
      performance.clearMarks(endMark);
    }
  }

  /**
   * Convenience method to measure an async function.
   */
  async measureAsync<T>(name: string, fn: () => Promise<T>): Promise<T> {
    const start = this.startMeasure(name);
    try {
      return await fn();
    } finally {
      this.endMeasure(name, start);
    }
  }

  /**
   * Convenience method to measure a sync function.
   */
  measureSync<T>(name: string, fn: () => T): T {
    const start = this.startMeasure(name);
    try {
      return fn();
    } finally {
      this.endMeasure(name, start);
    }
  }

  /**
   * Get all entries for a specific metric name.
   */
  getEntries(name?: string): MetricEntry[] {
    if (!name) return [...this.entries];
    return this.entries.filter((e) => e.name === name);
  }

  /**
   * Get statistics for a specific metric.
   */
  getStats(name: string): MetricStats | undefined {
    const matching = this.entries.filter((e) => e.name === name);
    if (matching.length === 0) return undefined;

    const durations = matching.map((e) => e.duration);
    return calculateStats(name, durations);
  }

  /**
   * Get statistics for all metrics.
   */
  getAllStats(): Record<string, MetricStats> {
    const names = [...new Set(this.entries.map((e) => e.name))];
    const stats: Record<string, MetricStats> = {};

    for (const name of names) {
      const stat = this.getStats(name);
      if (stat) stats[name] = stat;
    }

    return stats;
  }

  /**
   * Get unique metric names.
   */
  getMetricNames(): string[] {
    return [...new Set(this.entries.map((e) => e.name))];
  }

  /**
   * Get entry count.
   */
  getEntryCount(): number {
    return this.entries.length;
  }

  /**
   * Clear all entries.
   */
  clear(): void {
    this.entries = [];
  }

  /**
   * Close the collector and disconnect observer.
   */
  close(): void {
    if (this.observer) {
      this.observer.disconnect();
      this.observer = undefined;
    }
  }
}

// Singleton instance for global metrics
let globalCollector: MetricsCollector | undefined;

/**
 * Get the global metrics collector instance.
 */
export function getMetricsCollector(): MetricsCollector {
  if (!globalCollector) {
    globalCollector = new MetricsCollector();
  }
  return globalCollector;
}

/**
 * Helper to start a measurement using global collector.
 */
export function startMeasure(name: string): string {
  return getMetricsCollector().startMeasure(name);
}

/**
 * Helper to end a measurement using global collector.
 */
export function endMeasure(name: string, startMark: string): number {
  return getMetricsCollector().endMeasure(name, startMark);
}
```

**src/metrics/exporter.ts:**
```typescript
import { writeFileSync, existsSync, mkdirSync, readdirSync, unlinkSync } from "node:fs";
import { join, dirname } from "node:path";
import { MetricsCollector, getMetricsCollector } from "./collector.js";
import type { MetricStats } from "./stats.js";
import type { MetricEntry } from "./collector.js";

export interface MetricsExport {
  exportedAt: string;
  totalEntries: number;
  metrics: string[];
  entries: MetricEntry[];
  statistics: Record<string, MetricStats>;
}

/**
 * Export metrics to JSON file (HARD-05).
 */
export function exportMetrics(
  collector?: MetricsCollector,
  outputPath?: string
): string {
  const metricsCollector = collector || getMetricsCollector();
  const basePath = process.cwd();
  const metricsDir = join(basePath, ".msw");
  const filePath = outputPath || join(metricsDir, `metrics-${Date.now()}.json`);

  // Ensure directory exists
  const dir = dirname(filePath);
  if (!existsSync(dir)) {
    mkdirSync(dir, { recursive: true });
  }

  const exportData: MetricsExport = {
    exportedAt: new Date().toISOString(),
    totalEntries: metricsCollector.getEntryCount(),
    metrics: metricsCollector.getMetricNames(),
    entries: metricsCollector.getEntries(),
    statistics: metricsCollector.getAllStats(),
  };

  writeFileSync(filePath, JSON.stringify(exportData, null, 2));
  return filePath;
}

/**
 * Export metrics and clear the collector.
 */
export function exportAndClear(
  collector?: MetricsCollector,
  outputPath?: string
): string {
  const filePath = exportMetrics(collector, outputPath);
  const metricsCollector = collector || getMetricsCollector();
  metricsCollector.clear();
  return filePath;
}

/**
 * Prune old metrics files, keeping only the last N files.
 */
export function pruneMetricsFiles(
  keepCount: number = 7,
  basePath: string = process.cwd()
): number {
  const metricsDir = join(basePath, ".msw");

  if (!existsSync(metricsDir)) {
    return 0;
  }

  // Find all metrics files
  const files = readdirSync(metricsDir)
    .filter((f) => f.startsWith("metrics-") && f.endsWith(".json"))
    .sort()
    .reverse(); // Newest first

  // Remove files beyond keepCount
  const toRemove = files.slice(keepCount);
  let removed = 0;

  for (const file of toRemove) {
    try {
      unlinkSync(join(metricsDir, file));
      removed++;
    } catch {
      // Ignore removal errors
    }
  }

  return removed;
}

/**
 * Get list of existing metrics export files.
 */
export function listMetricsFiles(basePath: string = process.cwd()): string[] {
  const metricsDir = join(basePath, ".msw");

  if (!existsSync(metricsDir)) {
    return [];
  }

  return readdirSync(metricsDir)
    .filter((f) => f.startsWith("metrics-") && f.endsWith(".json"))
    .map((f) => join(metricsDir, f))
    .sort()
    .reverse(); // Newest first
}
```

**src/metrics/index.ts:**
```typescript
// Barrel export for metrics module
export {
  MetricsCollector,
  getMetricsCollector,
  startMeasure,
  endMeasure,
  type MetricEntry,
} from "./collector.js";

export {
  calculateStats,
  percentile,
  standardDeviation,
  formatStats,
  type MetricStats,
} from "./stats.js";

export {
  exportMetrics,
  exportAndClear,
  pruneMetricsFiles,
  listMetricsFiles,
  type MetricsExport,
} from "./exporter.js";
```
  </action>
  <verify>
- `npx tsc --noEmit` passes
- `ls src/metrics/` shows 4 files
- Test: Create collector, start/end a measure, export to JSON - file should be created
  </verify>
  <done>
- MetricsCollector uses perf_hooks for high-resolution timing
- startMeasure/endMeasure provide simple measurement API
- measureAsync/measureSync convenience methods for automatic timing
- JSON export includes entries and statistical aggregations
- Memory leak prevention via MAX_ENTRIES limit
  </done>
</task>

</tasks>

<verification>
After completion:
1. Run `npx tsc --noEmit` - should pass without errors
2. Test metrics collection:
   - Start measure, perform operation, end measure
   - Verify entry is recorded
3. Test export: Call exportMetrics() and verify JSON file in .msw/
4. Test statistics: Record multiple entries, verify p50/p95/p99 calculations
</verification>

<success_criteria>
- src/metrics/ module exports MetricsCollector, exportMetrics
- Performance measured using Node.js perf_hooks (non-blocking)
- Statistics include min/max/avg/p50/p90/p95/p99/stdDev
- JSON export saves to .msw/metrics-*.json
- Memory bounded by MAX_ENTRIES limit
</success_criteria>

<output>
After completion, create `.planning/phases/09-production-hardening/09-05-SUMMARY.md`
</output>
