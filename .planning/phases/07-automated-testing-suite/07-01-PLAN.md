---
phase: 07-automated-testing-suite
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - vitest.config.ts
  - package.json
  - tests/setup.ts
  - tsconfig.test.json
autonomous: true

must_haves:
  truths:
    - "Vitest runs tests and generates coverage reports"
    - "Coverage thresholds are enforced on critical paths"
    - "Test scripts are available for watch, run, and coverage modes"
  artifacts:
    - path: "vitest.config.ts"
      provides: "Coverage configuration with thresholds"
      contains: "coverage.*provider.*v8"
    - path: "package.json"
      provides: "Test scripts (test, test:watch, test:coverage)"
      contains: "test:coverage"
    - path: "tests/setup.ts"
      provides: "Global test setup and utilities"
      min_lines: 10
  key_links:
    - from: "vitest.config.ts"
      to: "@vitest/coverage-v8"
      via: "provider configuration"
      pattern: "provider.*v8"
---

<objective>
Establish Vitest test infrastructure with coverage reporting and enforcement for comprehensive automated testing.

**Purpose:** Provides the foundation for all unit, integration, and E2E tests with coverage tracking and threshold enforcement on critical paths (auth, backup, browser, MCP tools).

**Output:** Fully configured Vitest environment with coverage reporting, test scripts, and per-module thresholds targeting 80%+ on critical paths.
</objective>

<execution_context>
@C:\Users\lucid\.claude\get-shit-done\workflows\execute-plan.md
@C:\Users\lucid\.claude\get-shit-done\templates\summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-automated-testing-suite/07-RESEARCH.md

# Current state
@vitest.config.ts
@package.json
@tests/e2e/mcp-client.test.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install coverage dependencies</name>
  <files>package.json</files>
  <action>
Install Vitest coverage provider and UI:

```bash
npm install -D @vitest/coverage-v8 @vitest/ui
```

This adds V8 coverage reporting (native, fast) and optional test UI dashboard for development.
  </action>
  <verify>
```bash
npm list @vitest/coverage-v8 @vitest/ui
```
Both packages should appear in devDependencies.
  </verify>
  <done>@vitest/coverage-v8 and @vitest/ui are installed as devDependencies</done>
</task>

<task type="auto">
  <name>Task 2: Configure Vitest with coverage thresholds</name>
  <files>vitest.config.ts, tsconfig.test.json</files>
  <action>
Update `vitest.config.ts` to add coverage configuration:

```typescript
import { defineConfig } from "vitest/config";

export default defineConfig({
  test: {
    include: ["tests/**/*.test.ts"],
    testTimeout: 30_000,
    coverage: {
      provider: "v8",
      reporter: ["text", "json", "html", "lcov"],
      include: ["src/**/*.ts"],
      exclude: [
        "src/**/*.test.ts",
        "src/**/index.ts", // Barrel exports
        "src/types/**", // Type definitions
      ],
      thresholds: {
        // Global thresholds
        lines: 70,
        functions: 70,
        branches: 65,
        statements: 70,
        // Per-module thresholds for critical paths (80%+)
        "src/auth/**/*.ts": {
          lines: 80,
          functions: 80,
          branches: 75,
        },
        "src/backup/**/*.ts": {
          lines: 80,
          functions: 80,
          branches: 75,
        },
        "src/config/**/*.ts": {
          lines: 80,
          functions: 80,
          branches: 75,
        },
        "src/common/degradation.ts": {
          lines: 80,
          functions: 80,
          branches: 75,
        },
        "src/browser/driver.ts": {
          lines: 85,
          functions: 85,
        },
        "src/mcp/tools/**/*.ts": {
          lines: 80,
          functions: 80,
        },
      },
    },
    globals: true,
    environment: "node",
    setupFiles: ["./tests/setup.ts"],
  },
});
```

Create `tsconfig.test.json` for test-specific TypeScript config:

```json
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "types": ["vitest/globals", "node"]
  },
  "include": ["tests/**/*.ts", "src/**/*.ts"]
}
```

**Why these thresholds:**
- Global 70% provides baseline safety net
- Critical paths (auth, backup, config, degradation, browser driver, MCP tools) get 80%+ per research recommendation
- Browser driver gets 85% due to high risk of bot detection failures
  </action>
  <verify>
```bash
# Check config syntax
npm run test -- --run --reporter=verbose
```
No config errors, coverage thresholds appear in output.
  </verify>
  <done>vitest.config.ts has coverage configuration with per-module thresholds and tsconfig.test.json exists</done>
</task>

<task type="auto">
  <name>Task 3: Add test scripts and global setup</name>
  <files>package.json, tests/setup.ts</files>
  <action>
Add test scripts to `package.json`:

```json
{
  "scripts": {
    "test": "vitest run",
    "test:watch": "vitest",
    "test:coverage": "vitest run --coverage",
    "test:ui": "vitest --ui"
  }
}
```

Create `tests/setup.ts` for global test utilities:

```typescript
import { beforeAll, afterAll } from "vitest";
import fs from "node:fs";
import path from "node:path";
import os from "node:os";

// Global test timeout extension for E2E tests
beforeAll(() => {
  // Ensure temp directories are clean
  const tmpBase = path.join(os.tmpdir(), "msw-test-");
  const staleTests = fs.readdirSync(os.tmpdir()).filter((dir) =>
    dir.startsWith("msw-test-") || dir.startsWith("msw-e2e-")
  );

  // Clean up stale test directories older than 1 hour
  const oneHourAgo = Date.now() - 3600_000;
  staleTests.forEach((dir) => {
    const fullPath = path.join(os.tmpdir(), dir);
    try {
      const stats = fs.statSync(fullPath);
      if (stats.mtime.getTime() < oneHourAgo) {
        fs.rmSync(fullPath, { recursive: true, force: true });
      }
    } catch (e) {
      // Ignore errors (directory may be in use)
    }
  });
});

afterAll(() => {
  // Global cleanup runs after all tests
});

/**
 * Create a unique temporary directory for a test
 */
export function createTestDir(prefix = "msw-test"): string {
  return fs.mkdtempSync(
    path.join(os.tmpdir(), `${prefix}-${Date.now()}-`)
  );
}

/**
 * Clean up a test directory
 */
export function cleanupTestDir(dir: string): void {
  if (fs.existsSync(dir)) {
    fs.rmSync(dir, { recursive: true, force: true });
  }
}
```

**Why these utilities:**
- Cleanup stale test directories to prevent tmp pollution
- Shared utilities reduce boilerplate in individual tests
- Global hooks ensure consistent test environment
  </action>
  <verify>
```bash
# Verify scripts work
npm run test:watch -- --run
npm run test:coverage -- --run

# Check setup file is loaded
cat tests/setup.ts
```
Scripts execute without errors, setup.ts utilities are defined.
  </verify>
  <done>package.json has test scripts (test, test:watch, test:coverage, test:ui) and tests/setup.ts provides global utilities</done>
</task>

</tasks>

<verification>
**Infrastructure checks:**
1. Run `npm run test:coverage` - should execute (may have 0 tests, that's OK)
2. Check `vitest.config.ts` has coverage.provider = "v8" and thresholds defined
3. Verify `tests/setup.ts` exports createTestDir and cleanupTestDir utilities
4. Confirm package.json has all 4 test scripts (test, test:watch, test:coverage, test:ui)

**Coverage directory:**
- Running `npm run test:coverage` should create `coverage/` directory with HTML reports
</verification>

<success_criteria>
**Infrastructure is ready when:**
1. Vitest runs without configuration errors
2. Coverage reporting generates HTML/JSON/LCOV output in `coverage/`
3. Critical path thresholds (auth, backup, config, degradation, browser driver, MCP tools) are configured at 80%+
4. Global test utilities (createTestDir, cleanupTestDir) are available for all tests
5. Test scripts (test, test:watch, test:coverage, test:ui) work correctly
</success_criteria>

<output>
After completion, create `.planning/phases/07-automated-testing-suite/07-01-SUMMARY.md` with:
- Vitest configuration details (coverage provider, thresholds, reporters)
- Test scripts added to package.json
- Global utilities available in tests/setup.ts
- Next steps: Write unit tests for critical modules (07-02)
</output>
